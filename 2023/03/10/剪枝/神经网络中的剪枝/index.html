<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
	<link rel="dns-prefetch" href="//cdn.bootcss.com" />
	<link rel="dns-prefetch" href="//cdn.mathjax.org" />
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="Caaaaa">
    
    <title>
        
            神经网络中的剪枝 |
        
        Caaaaa
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="shortcut icon" href="/images/logo.png">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/css/font-awesome.min.css">
    <script id="hexo-configurations">
    let KEEP = window.KEEP || {};
    KEEP.hexo_config = {"hostname":"caaaa-a.github.io","root":"/","language":"en","path":"search.json"};
    KEEP.theme_config = {"toc":{"enable":true,"number":false,"expand_all":false,"init_open":true},"style":{"primary_color":"#0066CC","avatar":"/images/logo.png","favicon":"/images/logo.png","article_img_align":"left","left_side_width":"260px","content_max_width":"920px","hover":{"shadow":true,"scale":true},"first_screen":{"enable":true,"background_img":"/images/bg.svg","description":"To be a slash youth."},"scroll":{"progress_bar":{"enable":true},"percent":{"enable":true}}},"local_search":{"enable":true,"preload":true},"code_copy":{"enable":false,"style":"default"},"pjax":{"enable":false},"lazyload":{"enable":false},"version":"3.4.5"};
    KEEP.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
  </script>
<meta name="generator" content="Hexo 6.0.0"></head>


<body>
<div class="progress-bar-container">
    
        <span class="scroll-progress-bar"></span>
    

    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            <header class="header-wrapper">

    <div class="header-content">
        <div class="left">
            
            <a class="logo-title" href="/">
                Caaaaa
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            <a class=""
                               href="/"
                            >
                                HOME
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/archives"
                            >
                                ARCHIVES
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/categories"
                            >
                                CATEGORIES
                            </a>
                        </li>
                    
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="fas fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/">HOME</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/archives">ARCHIVES</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/categories">CATEGORIES</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="article-content-container">

        <div class="article-title">
            <span class="title-hover-animation">神经网络中的剪枝</span>
        </div>

        
            <div class="article-header">
                <div class="avatar">
                    <img src="/images/logo.png">
                </div>
                <div class="info">
                    <div class="author">
                        <span class="name">Caaaaa</span>
                        
                            <span class="author-label">Lv5</span>
                        
                    </div>
                    <div class="meta-info">
                        <div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fas fa-edit"></i>&nbsp;
        <span class="pc">2023-03-10 15:22:50</span>
        <span class="mobile">2023-03-10 15:22</span>
    </span>
    
        <span class="article-categories article-meta-item">
            <i class="fas fa-folder"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/categories/%E5%89%AA%E6%9E%9D/">剪枝</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    
    

    
    
        <span class="article-wordcount article-meta-item">
            <i class="fas fa-file-word"></i>&nbsp;<span>5.9k Words</span>
        </span>
    
    
        <span class="article-min2read article-meta-item">
            <i class="fas fa-clock"></i>&nbsp;<span>21 Mins</span>
        </span>
    
    
        <span class="article-pv article-meta-item">
            <i class="fas fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                    </div>
                </div>
            </div>
        

        <div class="article-content markdown-body">
            <h3 id="简介">简介</h3>
<p>剪枝顾名思义，就是删去一些不重要的节点，来减小计算或搜索的复杂度。剪枝在很多算法中都有很好的应用，如：决策树，神经网络，搜索算法，数据库的设计等。在决策树和神经网络中，剪枝可以有效缓解过拟合问题并减小计算复杂度；在搜索算法中，可以减小搜索范围，提高搜索效率。</p>
<p>在神经网络的训练过程中，为了选择合适的大小的神经网络，有两种方法。</p>
<ul>
<li><p>第一种，由小的神经网络慢慢的加入新的隐含层来扩大神经网络结构。</p></li>
<li><p>第二种，由一个较大的神经网络结构通过剪枝来获得较为何时大小的神经网络。</p></li>
</ul>
<p>而剪枝算法就是应用于第二种方法中。<strong>剪枝采用自顶而下的设计方式，先构建一个足够大的网络，然后通过在训练时删除或合并某些节点或者权值来达到精简网络结构的目的。</strong></p>
<h4 id="过参数化">过参数化</h4>
<p>具体来说，深度学习网络模型从卷积层到全连接层存在着<strong>大量冗余的参数，大量神经元激活值趋近于0，将这些神经元去除后可以表现出同样的模型表达能力</strong>，这种情况被称为<strong>过参数化</strong>，而对应的技术则被称为模型剪枝。</p>
<h3 id="必要性">必要性</h3>
<ul>
<li><p>在《To prune, or not to prune: exploring the efficacy of pruning for model compression》中探讨了具有<strong>同等参数量</strong>的稀疏大模型和稠密小模型的性能对比，<strong>在图像和语音任务上表明稀疏大模型普遍有更好的性能。</strong></p></li>
<li><p>神经网络的高计算量和高存储花费使得它在边缘计算很难部署。</p></li>
</ul>
<h3 id="主要步骤">主要步骤</h3>
<p><strong>（1）</strong> 进行正常的网络训练；</p>
<p><strong>（2）</strong> 删除所有权重小于一定阈值的连接；</p>
<p><strong>（3）</strong> 对上面得到的稀疏连接网络再训练；</p>
<h3 id="经典方法简单介绍">经典方法（简单介绍）</h3>
<p><strong>权衰减法：</strong>它通过在网络目标函数中引入代表结构复杂性的正则化项来达到减低网络结构复杂性的目的。通常的目标函数如下，其中 <span class="math inline">\(E(W)\)</span> 通常取网络误差平方和，<span class="math inline">\(C(W)\)</span> 为网络的复杂性。 <span class="math display">\[
J(W)=E(W)+\lambda C(W)
\]</span> <strong>灵敏度计算方法（Sensitivity Calculations）：</strong>该方法是指在网络进行训练时，或在网络训练结束后，<strong>计算节点（输入节点及隐节点）或连接权对网络误差的贡献</strong>，即灵敏度，删除那些贡献小的节点或权。</p>
<p><strong>相关性剪枝方法</strong>：最常见的相关性剪枝方法是先判断隐节点输出之间的相关性，然后合并具有较大相关性的隐节点。</p>
<p><strong>Dropout </strong>和 <strong>DropConnect </strong>：</p>
<ul>
<li><p>Dropout中随机的将一些神经元的输出置零，这就是<strong>神经元剪枝</strong>。</p></li>
<li><p>DropConnect则随机的将一些神经元之间的连接置零，使得权重连接矩阵变得稀疏，这便是<strong>权重连接剪枝</strong>。</p></li>
<li><p>它们是最细粒度的剪枝技术。</p></li>
</ul>
<h4 id="for-cnn">For CNN</h4>
<p><strong>根据粒度的不同，可以粗分为4个粒度</strong></p>
<ul>
<li>细粒度剪枝(fine-grained)：即对连接或者神经元进行剪枝，它是粒度最小的剪枝。</li>
<li>向量剪枝(vector-level)：它相对于细粒度剪枝粒度更大，属于对卷积核内部(intra-kernel)的剪枝。</li>
<li>核剪枝(kernel-level)：即去除某个卷积核，它将丢弃对输入通道中对应计算通道的响应。</li>
<li>滤波器剪枝(Filter-level)：对整个卷积核组进行剪枝，会造成推理过程中输出特征通道数的改变。</li>
</ul>
<p><strong>结构化剪枝 OR 非结构化剪枝？</strong></p>
<p>细粒度剪枝(fine-grained)，向量剪枝(vector-level)，核剪枝(kernel-level)方法在参数量与模型性能之间取得了一定的平衡，但是网络的拓扑结构本身发生了变化，需要专门的算法设计来支持这种稀疏的运算，被称之为非结构化剪枝。</p>
<p>而滤波器剪枝(Filter-level)只改变了网络中的滤波器组和特征通道数目，所获得的模型不需要专门的算法设计就能够运行，被称为结构化剪枝。除此之外还有对整个网络层的剪枝，它可以被看作是滤波器剪枝(Filter-level)的变种，即所有的滤波器都丢弃。</p>
<h3 id="历史">历史</h3>
<p>神经网络的剪枝已经广泛的应用于CNN模型中。Mozer, Smol ensky 1989提出删除输入节点或隐节点的方法，当某节点的灵敏度低于预定的阈值时，便可以删除该节点，也就是<strong>灵敏度计算方法的经典算法</strong>。Sefee and carter 研究了该算法发现，即使系统有更小的参数也不会使得这个系统过于敏感。1990年，Karnin 提出一种删除权值的方法，该方法在神经网络学习中动态计算每个权值的灵敏度，因此计算量较小。Weight 等人基于Rissanen的最短描述长度来描述学习机器的复杂性，并提出权消去法（Weight-Elimination），该方法用于剪除网络中冗余的权值。Reed在1993年曾对早期的剪枝算法进行简单的分类。1993年，Hassibi等人提出的 Optimal Brain Surgeon 剪枝网络通过Hessian损失函数来减少关联，并且实验表明，算法比权衰减法要好。</p>
<p>但这些方法都需要事先知道一些信息才能断定神经网络的大小。之后，GA遗传，PSO等算法被应用于剪枝中，GA或PSO可以找出合适的隐含层数目或者节点数目。优化算法和神经网络的结合大大提高了神经网络的计算效率，也被称为iterative pruning。例如1997, Slawomir 等人使用随机优化算法对神经网络进行剪枝；</p>
<p>最近，因为深度学习是计算密集型和存储密集型的，这使得它难以被部署到只有有限硬件资源的嵌入式系统上。2015年，Han等人发现剪枝后的网络的参数的数目减小了一个数量级；并且提出了一个新的去除冗余的方式，“密集-稀疏-密集”（DSD）训练方法。</p>
<table>
<colgroup>
<col style="width: 3%" />
<col style="width: 48%" />
<col style="width: 48%" />
</colgroup>
<thead>
<tr class="header">
<th>年份</th>
<th>事件/神经网络</th>
<th>论文</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1989</td>
<td>Mozer, Smol ensky等人提出一种灵敏度计算方法应用于剪枝方法中</td>
<td>Mozer, M. C., &amp; Smolensky, P. (1989). Skeletonization: A technique for trimming the fat from a network via relevance assessment. In Advances in neural information processing systems (pp. 107-115).</td>
</tr>
<tr class="even">
<td>1991</td>
<td>Weigend等人提出权衰弱法进行剪枝</td>
<td>Weigend, A. S., Rumelhart, D. E., &amp; Huberman, B. A. (1991). Generalization by weight-elimination with application to forecasting. In Advances in neural information processing systems (pp. 875-882).</td>
</tr>
<tr class="odd">
<td>1993</td>
<td>Reed对经典的剪枝算法进行归纳验证，经典的pruning servey之一</td>
<td>Reed, R. (1993). Pruning algorithms-a survey. IEEE transactions on Neural Networks, 4(5), 740-747.</td>
</tr>
<tr class="even">
<td>2015</td>
<td>Han S基于剪枝提出了一个压缩神经网络的新方法</td>
<td>Han, S., Mao, H., &amp; Dally, W. J. (2015). A deep neural network compression pipeline: Pruning, quantization, huffman encoding. arXiv preprint arXiv:1510.00149, 10.</td>
</tr>
<tr class="odd">
<td>2015</td>
<td>Han S为了减小神经网络的高消耗，提出了DSD的三步骤剪除冗余的神经网络</td>
<td>Han, S., Pool, J., Tran, J., &amp; Dally, W. (2015). Learning both weights and connections for efficient neural network. In Advances in Neural Information Processing Systems (pp. 1135-1143).</td>
</tr>
</tbody>
</table>
<h3 id="发展分析">发展分析</h3>
<p>近年来，人工神经网络正向模拟人类认知的道路上更加深入发展，与模糊系统、遗传算法，成为人工智能的一个重要方向，将在实际应用中得到发展。将信息几何应用于人工神经网络的研究，为人工神经网络的理论研究开辟了新的途径。神经计算机的研究发展很快，已有产品进入市场。光电结合的神经计算机为人工神经网络的发展提供了良好条件。</p>
<p>神经网络在很多领域已得到了很好的应用，但其需要研究的方面还很多。其中，具有分布存储、并行处理、自学习、自组织以及非线性映射等优点的神经网络与其他技术的结合以及由此而来的混合方法和混合系统，已经成为一大研究热点。由于其他方法也有它们各自的优点，所以将神经网络与其他方法相结合，取长补短，继而可以获得更好的应用效果。目前这方面工作有神经网络与模糊逻辑、专家系统、遗传算法、小波分析、混沌、粗集理论、分形理论、证据理论和灰色系统等的融合。</p>
<p><strong>1. 重要性因子选择</strong></p>
<p>通过某种准则来判断一个连接或者通道是否重要，比如范数（L1，L2）。</p>
<p>缺陷：但这类方法的假设前提条件太强，需要权重和激活值本身满足一定的分布。</p>
<p><strong>2.</strong> <strong>剪枝流程优化</strong></p>
<p>当前大部分框架都是逐层进行剪枝，而没有让各层之间进行联动。</p>
<p>在当前阶段冗余的模块，并不意味着对其他阶段也是冗余的。</p>
<p>以NISP为代表的方法就通过反向传播来直接对整个网络神经元的重要性进行打分，一次性完成整个模型的剪枝。</p>
<p><strong>3.</strong> <strong>个性化剪枝</strong></p>
<p>模型在剪枝完后进行推理时不会发生变化，即对于所有的输入图片来说都是一样的计算量，但是有的样本简单，有的样本复杂。</p>
<p>----&gt;动态推理框架，可以对不同的输入样本图配置不同的计算量，剪枝框架也可以采用这样的思路。</p>
<p>以Runtime Neural Pruning 为代表。</p>
<p><strong>4.</strong> <strong>自动化剪枝</strong></p>
<p>在提取低级特征的参数较少的第一层中剪掉更少的参数，对冗余性更高的FC层剪掉更多的参数。</p>
<p>除此之外，还有训练前剪枝，注意力机制增强等等许多方向。</p>
<p>AutoML for Model Compression(AMC)是其中的代表。</p>
<h3 id="reference">Reference</h3>
<ol type="1">
<li><p><a class="link"   target="_blank" rel="noopener" href="https://www.jiqizhixin.com/graph/technologies/30ffd95b-36fa-4e6f-b863-926410835b10" >机器之心——剪枝<i class="fas fa-external-link-alt"></i></a>：剪枝（决策树，神经网络，搜索）的介绍、历史和发展分析</p></li>
<li><p><a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/Cai_deLong/article/details/111148033" >概览：快速入门神经网络剪枝！<i class="fas fa-external-link-alt"></i></a></p></li>
</ol>
<h3 id="一些词语解释">一些词语解释</h3>
<ol type="1">
<li>从头训练(Trrain From Scratch)：指只保留剪枝后的模型的结构，而不使用其剪枝后的权重。并随机初始化权重，再进行训练（通常使用和训练大模型时相同的学习率计划）。</li>
<li>微调(Finetune)：剪枝后的模型使用小学习率继续训练。</li>
</ol>
<h3 id="补充一点模型压缩中的剪枝">补充一点模型压缩（中的剪枝）</h3>
<p>可以理解成剪枝的上层概念。目的和背景基本和剪枝是一致的，压缩模型以最大限度地减小模型对于计算空间和时间的消耗。而且它是软件方法，应用成本低，而且与硬件加速方法并不矛盾，可以相互加成。</p>
<h4 id="目前方法">目前方法</h4>
<p>从数据，模型和硬件多维度的层面来分析，压缩和加速模型的方法</p>
<p><strong>1、</strong> <strong>压缩已有的网络，包含：张量分解，模型剪枝，模型量化；（针对既有模型）</strong></p>
<p><strong>2、 构建新的小型网络，包含：知识蒸馏，紧凑网络设计；（针对新模型）</strong></p>
<blockquote>
<p><strong>剪枝（Pruning）、量化（Quantization）、低秩分解（Low-rank factorization）、知识蒸馏（Knowledge distillation）</strong></p>
<p>1）pruning 2）quantization 3） knowledge distillation 4）low-rank decomposition 5）compact architecture design</p>
</blockquote>
<h4 id="剪枝思路">剪枝思路</h4>
<ol type="1">
<li><p>最简单的启发就是按参数（或特征输出）绝对值大小来评估重要性，这种方法叫<strong>magnitude-based weight pruning</strong>。（通常靠L1、group LASSO、activation）</p>
<blockquote>
<p>有个假设是参数绝对值越小，其对最终结果影响越小。我们称之为’‘smaller-norm-less-important’'准则。然而这个假设未必成立（如2018年的论文《Rethinking the Smaller-Norm-Less-Informative Assumption in Channel Pruning of Convolution Layers》有对其的讨论）。</p>
</blockquote></li>
<li><p>考虑<strong>参数裁剪对loss的影响</strong>。</p>
<blockquote>
<p><strong>其实前面提到的始祖级的OBD和OBS就是属于此类</strong>。但这两种方法需要计算Hessian矩阵或其近似比较费时。近年来有一些基于该思路的方法被研究和提出。如2016年论文《Pruning Convolutional Neural Networks for Resource Efficient Transfer Learning》也是基于Taylor expansion，但采用的是目标函数相对于activation的展开式中一阶项的绝对值作为pruning的criteria。这样就避免了二阶项（即Hessian矩阵）的计算。2018年论文《SNIP: Single-shot Network Pruning based on Connection Sensitivity》将归一化的目标函数相对于参数的导数绝对值作为重要性的衡量指标。</p>
</blockquote></li>
<li><p>考虑对<strong>特征输出的可重建性</strong>的影响，即最小化裁剪后网络对于特征输出的重建误差。它的intuition是如果对当前层进行裁剪，然后如果它对后面输出还没啥影响，那说明裁掉的是不太重要的信息。</p>
<blockquote>
<p>典型的如2017年论文《ThiNet: A Filter Level Pruning Method for Deep Neural Network Compression》和《Channel pruning for accelerating very deep neural networks》都是通过最小化特征重建误差（Feature reconstruction error）来确定哪些channel需要裁剪。前者采用贪心法，后者用的LASSO regression。2017年论文《NISP: Pruning Networks using Neuron Importance Score Propagation》提出只考虑后面一两层啥的不够，于是提出NISP（Neuron importance score propagation）算法通过最小化分类网络倒数第二层的重建误差，并将重要性信息反向传播到前面以决定哪些channel需要裁剪。2018年论文《Discrimination-aware Channel Pruning for Deep Neural Networks》提出一种比较有意思的变体。它提出DCP（Discrimination-aware channel pruning）方法一方面在中间层添加额外的discrimination-aware loss（用以强化中间层的判别能力），另一方面也考虑特征重建误差的loss，综合两方面loss对于参数的梯度信息，决定哪些为需要被裁剪的channel。</p>
</blockquote></li>
<li><p>基于其它的准则对权重进行重要性排序。</p></li>
<li><p><strong>基于梯度的方法。</strong>回顾上面问题定义中的数学最优化问题，其最恶心的地方在于regularizer中那个L0-norm，使目标不可微，从而无法用基于梯度的方法来求解。如2017年的论文《Learning Sparse Neural Networks through L0 Regularization》的思路是用一个连续的分布结合 hard-sigmoid recification去近似它，从而使目标函数平滑，这样便可以用基于梯度的方法求解。</p></li>
</ol>
<h4 id="sparsity-ratio">Sparsity Ratio</h4>
<p>上面研究的是给定裁剪量的前提下如何做pruning，如采用什么样的criteria去做参数选取。然而其实还有个核心问题是在哪里裁剪多少，即sparsity ratio的确定。这里的sparsity ratio定义为层中为0参数所占比例，有些文章中也称为pruning rate等。从目标结构或者sparsity ratio的指定方式来说，按2018年论文《Rethinking the Value of Network Pruning》中的说法可分为预定义（<strong>predifined</strong>）和自动（<strong>automatic</strong>）两种方式。Predefined方法由人工指定每一层的比例进行裁剪，因此目标结构是提前确定。而automatic方法会根据所有的layer信息（即全局信息）由pruning算法确定每层裁剪比例，因此目标结构一开始并不确定。</p>
<h4 id="精度恢复">精度恢复</h4>
<p>当模型经过pruning，一般会带来精度损失，因此我们在pruning的同时也需要考虑精度的恢复：前面提到的论文《Channel Pruning for Accelerating Very Deep Neural Networks》中在进行channel pruning后，直接通过least square来得到最小化特征重建精度下的新参数，因此不需要fine-tuning来恢复精度，是一种<strong>inference-time pruning</strong>方法。</p>
<p><strong>人们发现裁完后进行fine-tuning可以弥补pruning带来的精度损失，因此很多方法会在pruning后做fine-tuning。比较经典的是training，pruning，fine-tuning三段式。后面两个阶段交替进行，每次pruning后损失的精度可以由后面的fine-tuning来弥补，该过程也称为iterative pruning。</strong>简单说就是砍一刀回点血，再砍一刀再回点血这样，不一步到位是因为有些实验表明一下子砍太狠就难回血了。当然现实中可以衍生出很多玩法。而在时间维度上，每步砍多少也是有艺术的。</p>
<blockquote>
<p>如2017年论文《To Prune, or Not to Prune: Exploring the Efficacy of Pruning for Model Compression》提出一种automated gradual pruning算法，<strong>它基于开始阶段冗余多可以裁得快，越到后面越裁得快的指导思想，给出在n步的pruning中，如何从初始sparsity ratio渐变到目标sparsity ratio的方法。</strong></p>
</blockquote>
<h4 id="重新审视假设">重新审视假设</h4>
<p>比较有意思的是，最近不少工作开始反思一些之前固有的假设。比如一开始提到的<strong>over-parameterization对训练是否真的那么有益</strong>，还有<strong>原网络的权重是否在pruning中很重要</strong>。</p>
<blockquote>
<p>在ICLR2019的best paper《The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks》提出The Lottery Ticket Hypothesis，即一个随机初始化，密集的网络包含一个子网络，这个子网络如果沿用原网络的权重初始化，在至多同样迭代次数训练后就可以比肩原网络的测试精度。同时它还给出了找这种子网络结构的方法。文章认为这个子结构和它的初始值对训练的有效性至关重要，它们被称为『winning logttery tickets』。</p>
<p>另一篇论文2018年的《Rethinking the Value of Network Pruning》提出<del>不仅</del>over-parameterization对于训练不是重要的，<del>而且从原网络中重用其权重也未必是很好的选择，它可能会使裁剪后的模型陷入局部最小。</del>如果原网络的权重或其初始值不重要的话，那剩下最重要的就是pruning后的网络结构了。换句话说，某种意义上来说，pruning即是neural architecture search（NAS），只是由于它只涉及层的维度，搜索空间相比小一些。但这也是它的优点，搜索空间小了自然搜索就高效了。（详见：<a class="link"   target="_blank" rel="noopener" href="https://www.zhihu.com/question/303922732" >为什么要压缩模型，而不是直接训练一个小的CNN？<i class="fas fa-external-link-alt"></i></a>的高赞回答）</p>
</blockquote>
<h4 id="保留模型capacity">保留模型Capacity</h4>
<p>之前的主流pruning方法中，一旦有参数被不适当地裁剪掉，便无法被恢复。而这两年，学界正在尝试<strong>在模型压缩过程中保留被裁剪部分能力或者扩充能力的方法</strong>。</p>
<blockquote>
<p>2018年论文《Soft Filter Pruning for Accelerating Deep Convolutional Neural Networks》提出SFP（Soft filter pruning）让被裁剪的filter在训练中仍能被更新，这样它仍有机会被恢复回来。</p>
<p>2016年论文《Dynamic Network Surgery for Efficient DNNs》在pruning的基础上加了splicing操作，避免不合适的pruning带来的影响。</p>
<p>2017年的论文《Morphnet: Fast &amp; Simple Resource-Constrained Structure Learning of Deep Networks》也是基于这种思路，它会迭代地进行shrink和expand的操作。</p>
</blockquote>
<p>Pruning的副作用就是可能会损害模型的capacity。尽管前面的各种方法让该影响尽可能小，<strong>但我们往往只能在有限的数据集上做。</strong>因此，很可能对于大部分简单的样本pruning对其没有影响，但对于小部分难的数据会有较大影响。那有没有可能在保留网络capacity的同时又能精简计算呢？一些学者尝试<strong>结合dynamic NN</strong>来达到该目的，即网络执行哪些模块由输出决定。</p>
<blockquote>
<p>如2017年论文《Dynamic Deep Neural Networks: Optimizing Accuracy-Efficiency Trade-offs by Selective Execution》引入Dynamic Deep Neural Networks，对于给定输入，哪部分神经元被执行由网络本身中的controller module来确定。这个module通过强化学习进行训练。</p>
<p>另一篇2017年论文《Runtime Neural Pruning》将pruning建模为马尔可夫决策过程（Markov decision process）并通过强化学习来学习pruning策略。当然，这类方法也有些局限，如由于保留了网络原始capacity，因此size不会减少。另外由于执行哪部分是动态的，因此对于硬件加速会有影响（如算子间的fusion）。</p>
</blockquote>
<h4 id="方向">方向</h4>
<p><strong>方向一</strong></p>
<p>如前面提到，network pruning方法与NAS的界限已经模糊了。事实上，NAS分支上也有一类搜索加速方法，如One-Shot Architecture Search是先有一个大网络，然后做减法。NAS与模型压缩两个一开始看似关系不是那么大的分支最后似乎走到一块去了。这两个分支今天有了更多的交集，也必将擦出更多的火花。</p>
<p><strong>方向二</strong></p>
<p>挑战已有的固有的假设。如前面对于over-parameterization与重用已有参数是否有有益的反思非常有意思。这样的工作会给我们非常大的启发，从而根本改变解决问题的思路。</p>
<p><strong>方向三</strong></p>
<p>随着AutoML的大潮，越来越多的东西开始自动化。模型压缩能拉下吗？当然不能。经过前面的介绍我们知道，像ADC，RNP，N2N Learning这些工作都是试图将pruning中部分工作自动化。而且对于其它的模型压缩方法，如quantization，也有一些空间可以自动化，如2018年论文《HAQ: Hardware-Aware Automated Quantization》考虑网络中不同层信息的冗余程度不一样，因此可以用不同位数进行量化。</p>
<p><strong>方向四</strong></p>
<p>这几年机器学习最火热的分支之一GAN，正在不断渗透到已有领域，在pruning中也开始有它的身影。如2019年论文《Towards Optimal Structured CNN Pruning via Generative Adversarial Learning》采用了GAN的思想，让generator生成裁剪后网络，discrimintor来判别是否属于原网络还是裁剪后网络，从而进行更有效的网络结构化裁剪。</p>
<p><strong>方向五</strong></p>
<p>与硬件结合，如稀疏计算的支持。现在虽然有像cuSPARSE这样的计算库，但底层硬件GPU本身设计并不是专门为稀疏数据处理打造的。如果能将稀疏计算和处理能力做进芯片那必将极大提高计算效率，如早些年有像EIE这样的尝试。在现在神经网络芯片的大潮下，相信这样的案例会越来越多。</p>
<p><strong>方向六</strong></p>
<p>如文章一开始提到的，模型压缩方法中pruning只是其中一种，它与其它方法并不冲突，因此与其它方法，如knowledge distillation，quantization等的深度结合，是值得研究的方向。和其它机器学习分支一样，很多人提出很多算法，各家都说自家的好。一个分支发展到一定时候，就需要benchmark来进行客观的横向比较。Google在2019年论文《The State of Sparsity in Deep Neural Networks》正是这方面的尝试。相信以后也会有越来越多的benchmark，和针对性的竞赛。</p>
<p><strong>更多细节详见：</strong><a class="link"   target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/130645948" >深度学习网络模型压缩剪枝详细分析<i class="fas fa-external-link-alt"></i></a></p>
<h3 id="其他资源">其他资源</h3>
<ul>
<li><p><a class="link"   target="_blank" rel="noopener" href="https://nervanasystems.github.io/distiller/index.html" >Distiller<i class="fas fa-external-link-alt"></i></a>：一个使用PyTorch实现的剪枝工具包</p></li>
<li><p>https://www.cnblogs.com/chenbong/tag/Model%20Compression/</p></li>
<li><p><a class="link"   target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzIwNDgyNTc4NQ==&amp;mid=2247484207&amp;idx=1&amp;sn=bdec141fd3139a1d7ec8b111106d2232&amp;chksm=973b76f9a04cffef02fac731a92fd279e0f8c0488aa372c38dbbd247c78490b28d7a269d6e16&amp;scene=178&amp;cur_album_id=1416925159679950850#rd" >剪枝框架推荐第一波：腾讯自动化模型压缩框架PocketFlow<i class="fas fa-external-link-alt"></i></a></p></li>
<li><p><a class="link"   target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzIwNDgyNTc4NQ==&amp;mid=2247484255&amp;idx=1&amp;sn=76ecb5d33385c94e2d9028e52e7bd187&amp;chksm=973b7689a04cff9f5d87aa3270f8c3ff7fc76ccb3a1603466cadf8de42d86fa5d8fcd4cfd0c1&amp;scene=178&amp;cur_album_id=1416925159679950850#rd" >剪枝框架推荐第二弹，nni：不止是剪枝压缩工具<i class="fas fa-external-link-alt"></i></a></p></li>
<li><p>https://github.com/he-y/Awesome-Pruning</p></li>
</ul>

        </div>

        
            <div class="post-copyright-info">
                <div class="article-copyright-info-container">
    <ul>
        <li>Post title：神经网络中的剪枝</li>
        <li>Post author：Caaaaa</li>
        <li>Create time：2023-03-10 15:22:50</li>
        <li>
            Post link：https://caaaa-a.github.io/2023/03/10/剪枝/神经网络中的剪枝/
        </li>
        <li>
            Copyright Notice：All articles in this blog are licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">BY-NC-SA</a> unless stating additionally.
        </li>
    </ul>
</div>

            </div>
        

        

        
            <div class="article-nav">
                
                    <div class="article-prev">
                        <a class="prev"
                           rel="prev"
                           href="/2023/03/13/%E5%89%AA%E6%9E%9D/Learning-both-Weights-and-Connections-for-Efficient-Neural-Networks/"
                        >
                            <span class="left arrow-icon flex-center">
                              <i class="fas fa-chevron-left"></i>
                            </span>
                            <span class="title flex-center">
                                <span class="post-nav-title-item">Learning both Weights and Connections for Efficient Neural Networks</span>
                                <span class="post-nav-item">Prev posts</span>
                            </span>
                        </a>
                    </div>
                
                
                    <div class="article-next">
                        <a class="next"
                           rel="next"
                           href="/2023/02/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B0%8F%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%A1%B0%E5%87%8F/"
                        >
                            <span class="title flex-center">
                                <span class="post-nav-title-item">学习率衰减</span>
                                <span class="post-nav-item">Next posts</span>
                            </span>
                            <span class="right arrow-icon flex-center">
                              <i class="fas fa-chevron-right"></i>
                            </span>
                        </a>
                    </div>
                
            </div>
        

        
    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            <footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
              <span>2020</span>
              -
            
            2023&nbsp;<i class="fas fa-heart icon-animate"></i>&nbsp;<a href="/">Caaaaa</a>
        </div>
        
            <script async  src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    <span id="busuanzi_container_site_uv">
                        Visitor Count&nbsp;<span id="busuanzi_value_site_uv"></span>&ensp;
                    </span>
                
                
                    <span id="busuanzi_container_site_pv">
                        Totalview&nbsp;<span id="busuanzi_value_site_pv"></span>
                    </span>
                
            </div>
        
        <div class="theme-info info-item">
            Powered by <a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;|&nbsp;Theme&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.4.5</a>
        </div>
        
        
    </div>
</footer>

        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="tools-list">
        <!-- TOC aside toggle -->
        
            <li class="tools-item page-aside-toggle">
                <i class="fas fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
    </ul>
</div>

        </div>
    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-expand-width flex-center">
            <i class="fas fa-arrows-alt-h"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        

        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="arrow-up fas fa-arrow-up"></i>
                <span class="percent"></span>
            </li>
        
    </ul>
</div>

    </div>

    
        <aside class="page-aside">
            <div class="post-toc-wrap">
    <div class="post-toc">
        <ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AE%80%E4%BB%8B"><span class="nav-text">简介</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%87%E5%8F%82%E6%95%B0%E5%8C%96"><span class="nav-text">过参数化</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BF%85%E8%A6%81%E6%80%A7"><span class="nav-text">必要性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BB%E8%A6%81%E6%AD%A5%E9%AA%A4"><span class="nav-text">主要步骤</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BB%8F%E5%85%B8%E6%96%B9%E6%B3%95%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D"><span class="nav-text">经典方法（简单介绍）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#for-cnn"><span class="nav-text">For CNN</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8E%86%E5%8F%B2"><span class="nav-text">历史</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%91%E5%B1%95%E5%88%86%E6%9E%90"><span class="nav-text">发展分析</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#reference"><span class="nav-text">Reference</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E4%BA%9B%E8%AF%8D%E8%AF%AD%E8%A7%A3%E9%87%8A"><span class="nav-text">一些词语解释</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A1%A5%E5%85%85%E4%B8%80%E7%82%B9%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E4%B8%AD%E7%9A%84%E5%89%AA%E6%9E%9D"><span class="nav-text">补充一点模型压缩（中的剪枝）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%9B%AE%E5%89%8D%E6%96%B9%E6%B3%95"><span class="nav-text">目前方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%89%AA%E6%9E%9D%E6%80%9D%E8%B7%AF"><span class="nav-text">剪枝思路</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#sparsity-ratio"><span class="nav-text">Sparsity Ratio</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%B2%BE%E5%BA%A6%E6%81%A2%E5%A4%8D"><span class="nav-text">精度恢复</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%87%8D%E6%96%B0%E5%AE%A1%E8%A7%86%E5%81%87%E8%AE%BE"><span class="nav-text">重新审视假设</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BF%9D%E7%95%99%E6%A8%A1%E5%9E%8Bcapacity"><span class="nav-text">保留模型Capacity</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%96%B9%E5%90%91"><span class="nav-text">方向</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%B6%E4%BB%96%E8%B5%84%E6%BA%90"><span class="nav-text">其他资源</span></a></li></ol>
    </div>
</div>
        </aside>
    

    <div class="image-viewer-container">
    <img src="">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="Search..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="popup-btn-close">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>



<script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/utils.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/main.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/header-shrink.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/back2top.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/dark-light-toggle.js"></script>


    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/local-search.js"></script>






<div class="post-scripts">
    
        <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/left-side-toggle.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/libs/anime.min.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/toc.js"></script>
    
</div>



<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>

</body>
</html>
